{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b644f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820018bbe59b49b6b27e3c45ac423637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--unsloth--llava-1.5-7b-hf. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e2fe4c54ec447d96caa5797deba7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6a5c8071684b3b89f5834954395141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a050b7516b3a481fa0dde3560de3812a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0f332a3d2947eeb4d58f7c05f94fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "from typing import TypedDict\n",
    "from PIL import Image\n",
    "import requests, torch\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "\n",
    "# --- Model & Processor ---\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "\n",
    "model_id = \"unsloth/llava-1.5-7b-hf\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# requires accelerate installed\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    dtype=torch.float32  # CPU-friendly\n",
    ")\n",
    "model.to(\"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- State ---\n",
    "class State(TypedDict, total=False):\n",
    "    query: str\n",
    "    image: str          # URL or base64\n",
    "    category: str\n",
    "    sentiment: str\n",
    "    response: str\n",
    "\n",
    "# --- Simple text-only functions ---\n",
    "def categorize(state: State) -> State:\n",
    "    text = (\n",
    "        \"Categorize the following Kenya School of Government (KSG) customer query \"\n",
    "        \"into one of these categories: Admissions, Training, Certificates, General. \"\n",
    "        f\"Query: {state['query']}\"\n",
    "    )\n",
    "    inputs = processor(text=text, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        output = model.generate(**inputs, max_new_tokens=50)\n",
    "    return {\"category\": processor.decode(output[0], skip_special_tokens=True).strip()}\n",
    "\n",
    "def analyze_sentiment(state: State) -> State:\n",
    "    text = (\n",
    "        \"Analyze the sentiment of the following KSG customer query. \"\n",
    "        \"Respond with either 'Positive', 'Neutral', or 'Negative'. \"\n",
    "        f\"Query: {state['query']}\"\n",
    "    )\n",
    "    inputs = processor(text=text, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        output = model.generate(**inputs, max_new_tokens=50)\n",
    "    return {\"sentiment\": processor.decode(output[0], skip_special_tokens=True).strip()}\n",
    "\n",
    "# --- Multimodal handler ---\n",
    "def multimodal_handler(state: State, instruction: str) -> State:\n",
    "    text = (\n",
    "        f\"You are a Kenya School of Government support assistant. \"\n",
    "        f\"{instruction} Query: {state['query']}\"\n",
    "    )\n",
    "    if state.get(\"image\"):\n",
    "        image = Image.open(requests.get(state[\"image\"], stream=True).raw)\n",
    "    else:\n",
    "        image = None\n",
    "\n",
    "    inputs = processor(images=image, text=text, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        output = model.generate(**inputs, max_new_tokens=200)\n",
    "    answer = processor.decode(output[0], skip_special_tokens=True)\n",
    "    return {\"response\": answer.strip()}\n",
    "\n",
    "# --- Handlers ---\n",
    "def handle_admissions(state: State) -> State:\n",
    "    return multimodal_handler(state, \"Provide admissions/application support.\")\n",
    "\n",
    "def handle_training(state: State) -> State:\n",
    "    return multimodal_handler(state, \"Provide training/program information.\")\n",
    "\n",
    "def handle_certificates(state: State) -> State:\n",
    "    return multimodal_handler(state, \"Provide certificates/verification support.\")\n",
    "\n",
    "def handle_general(state: State) -> State:\n",
    "    return multimodal_handler(state, \"Provide general support.\")\n",
    "\n",
    "def escalate(state: State) -> State:\n",
    "    return {\"response\": \"This query has been escalated to a human KSG agent due to negative sentiment.\"}\n",
    "\n",
    "# --- Simple router ---\n",
    "def route_query(state: State) -> str:\n",
    "    if state.get('sentiment', '').strip().lower() == 'negative':\n",
    "        return \"escalate\"\n",
    "    category = state.get('category', '').strip().lower()\n",
    "    if \"admission\" in category:\n",
    "        return \"admissions\"\n",
    "    elif \"training\" in category or \"program\" in category:\n",
    "        return \"training\"\n",
    "    elif \"certificate\" in category or \"verification\" in category:\n",
    "        return \"certificates\"\n",
    "    else:\n",
    "        return \"general\"\n",
    "\n",
    "# --- Orchestrator ---\n",
    "def run_customer_support(query: str, image: str = None) -> dict:\n",
    "    \"\"\"Passes text and optional image URL through the workflow.\"\"\"\n",
    "\n",
    "    # step1 categorize\n",
    "    state: State = {\"query\": query, \"image\": image}\n",
    "    state.update(categorize(state))\n",
    "\n",
    "    # step2 sentiment\n",
    "    state.update(analyze_sentiment(state))\n",
    "\n",
    "    # step3 route\n",
    "    route = route_query(state)\n",
    "    if route == \"admissions\":\n",
    "        state.update(handle_admissions(state))\n",
    "    elif route == \"training\":\n",
    "        state.update(handle_training(state))\n",
    "    elif route == \"certificates\":\n",
    "        state.update(handle_certificates(state))\n",
    "    elif route == \"general\":\n",
    "        state.update(handle_general(state))\n",
    "    else:\n",
    "        state.update(escalate(state))\n",
    "\n",
    "    return {\n",
    "        \"category\": state.get(\"category\"),\n",
    "        \"sentiment\": state.get(\"sentiment\"),\n",
    "        \"response\": state.get(\"response\"),\n",
    "    }\n",
    "\n",
    "# --- Example usage ---\n",
    "output = run_customer_support(\n",
    "    \"How do I apply for the next leadership training at KSG?\",\n",
    "    image=\"https://example.com/sample_certificate.jpg\"\n",
    ")\n",
    "print(\"Category:\", output['category'])\n",
    "print(\"Sentiment:\", output['sentiment'])\n",
    "print(\"Response:\", output['response'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
